{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ec03a8",
   "metadata": {},
   "source": [
    "# Import Necessary Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbc349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PREPROCESSING FUNCTIONS FOR USE IN MODEL DEVELOPMENT, EVALUATION, AND PRODUCTION\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL as pil\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tempfile\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import skimage.filters\n",
    "import cv2\n",
    "import watermark\n",
    "import joblib\n",
    "from skimage.measure import block_reduce\n",
    "from image_preprocessing import standardize_image_dataset,binarize_dataset,crop_dataset,process_dataset_blur,do_pooling_dataset\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf205ffe",
   "metadata": {},
   "source": [
    "# Read in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dda326",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pickle.load(open('Amit/Labeled Data/train_data.pkl','rb'))\n",
    "X,y = training_data.iloc[:,:-1],training_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbc083",
   "metadata": {},
   "source": [
    "# Speed Tests of Image Preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c6f10",
   "metadata": {},
   "source": [
    "#### Binarization Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "310b78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (Automate Threshold): 298.4108188152313\n",
      "Time (Declare Threshold): 244.2928352355957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Speed Test When automating binarization threshold creating\n",
    "timer = time.time()\n",
    "binarization_speed_test_df = binarize_dataset(X)\n",
    "print('Time (Automate Threshold): ' + str(time.time() - timer))\n",
    "del binarization_speed_test_df\n",
    "gc.collect()\n",
    "\n",
    "#Speed Test When explicitly declaring threshold\n",
    "timer = time.time()\n",
    "binarization_speed_test_df = binarize_dataset(X,automate_threshold=False)\n",
    "print('Time (Declare Threshold): ' + str(time.time() - timer))\n",
    "del binarization_speed_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea345b3",
   "metadata": {},
   "source": [
    "#### Cropping/Edge Detection Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4efab5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 438.0091013908386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = time.time()\n",
    "cropping_speed_test_df = crop_dataset(X,(256,256),(256,256))\n",
    "print('Time: ' + str(time.time() - timer))\n",
    "del cropping_speed_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7aee5",
   "metadata": {},
   "source": [
    "#### Blurring Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "defa1c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (Gaussian Blur): 9.704895973205566\n",
      "Time (Box Blur): 7.284215211868286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Speed Test For Gaussian Blur on Image Dataset\n",
    "timer = time.time()\n",
    "gaussian_blur_speed_test_df = process_dataset_blur(X,blur_type='g',dimension=(256,256))\n",
    "print('Time (Gaussian Blur): ' + str(time.time() - timer))\n",
    "del gaussian_blur_speed_test_df\n",
    "gc.collect()\n",
    "\n",
    "#Speed Test For Box Blur on Image Dataset\n",
    "timer = time.time()\n",
    "box_blur_speed_test_df = process_dataset_blur(X,blur_type='b',dimension=(256,256))\n",
    "print('Time (Box Blur): ' + str(time.time() - timer))\n",
    "del box_blur_speed_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167fd77",
   "metadata": {},
   "source": [
    "#### Pooling Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f985f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (Max Pool): 48.6494026184082\n",
      "Time (Min Pool): 48.03231334686279\n",
      "Time (Mean Pool): 31.698415756225586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Speed Test Max Pooling\n",
    "timer = time.time()\n",
    "maxpool_speed_test_df = do_pooling_dataset(X,pooling_function=np.max)\n",
    "print('Time (Max Pool): ' + str(time.time() - timer))\n",
    "del maxpool_speed_test_df\n",
    "gc.collect()\n",
    "\n",
    "#Speed Test Min Pooling\n",
    "timer = time.time()\n",
    "minpool_speed_test_df = do_pooling_dataset(X,pooling_function=np.min)\n",
    "print('Time (Min Pool): ' + str(time.time() - timer))\n",
    "del minpool_speed_test_df\n",
    "gc.collect()\n",
    "\n",
    "#Speed Test Mean Pooling\n",
    "timer = time.time()\n",
    "meanpool_speed_test_df = do_pooling_dataset(X,pooling_function=np.mean)\n",
    "print('Time (Mean Pool): ' + str(time.time() - timer))\n",
    "del meanpool_speed_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b3dce",
   "metadata": {},
   "source": [
    "# Image Preprocessing, Model Evaluation/Development Pipeline\n",
    "The following pipeline will allow the user to pass in training data, declare preprocessing steps, and pass in a model alongside potential hyperparameters. The pipeline will then apply preprocessing steps to the training data, and then identify the best model/hyperparameter combination given the training data. Best in this case is the ability to maximize F1 score, balancing precision and recall ability for detecting class 1 (cancerous images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5183bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_pipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self = self\n",
    "    \n",
    "    def evaluate(self,X,y,preprocessing,model,param_grid,optimizing_metric,n_splits,\n",
    "                return_transformed_features = True, return_grid = True, return_score = True, return_best_estimator = True,\n",
    "                return_best_params = True,return_oos_pred = True, return_oos_prob = True, return_threshold_analysis=True):\n",
    "        \n",
    "        '''\n",
    "        The evaluate method allows the user to pass in labeled data (X,y) into the modeling pipeline \n",
    "        alongside user defined preprocessing steps, a model, and acceptable hyperparameters for the model.\n",
    "        \n",
    "        First, the method will apply preprocessing steps in the order they are defined. If no preprocessing steps\n",
    "        are necessary, then store an empty list: preprocesssing = []. By applying steps in the order they are defined\n",
    "        rather than presetting the order, this allows greater control and customization over the general image\n",
    "        cleaning process while also accounting for the ability of mixing orders in potentially improving resulting\n",
    "        model performance.\n",
    "        \n",
    "        To correctly execute an internal preprocessing step, pass in a tuple where index 0 contains one of 'binarize', 'crop',\n",
    "        'blur', and 'pool' while index 1 contains a list in order that defines values for all acceptable function\n",
    "        parameters for that specific preprocessing step. For example to execute:\n",
    "            - Binarization/Shade Removal, pass in ('binarize',[automate_threshold,t]) into the preprocessing list\n",
    "            - Cropping/Edge Detection, pass in ('crop',[old_dim,new_dim]) into the preprocessing list\n",
    "            - Blurring, pass in ('blur',[blur_type,dimension,kernel,sigma_x,sigma_y]) into the preprocessing list\n",
    "            - Pooling, pass in ('pool',[pool_size,pooling_function]) into the preprocessing list\n",
    "            \n",
    "        The user can combine as many or as few of the above preprocessing steps in an order of their choice. As a final\n",
    "        example, in order to execute binarization, cropping, blurring, and pooling on the feature data IN THAT ORDER, \n",
    "        the preprocessing list would have the following format:\n",
    "            - preprocessing = [('binarize',[automate_threshold,t]),\n",
    "                                 ('crop',[old_dim,new_dim]),\n",
    "                                 ('blur',[blur_type,dimension,kernel,sigma_x,sigma_y]),\n",
    "                                 ('pool',[pool_size,pooling_function])]\n",
    "        which with explicity defined values could be productionized with:\n",
    "            - preprocessing = [('binarize',[True,0.3]),\n",
    "                                 ('crop',[(256,256),(256,256)]),\n",
    "                                 ('blur',['g',(256,256),(5,5),0,0]),\n",
    "                                 ('pool',[(2,2),np.max])]\n",
    "        \n",
    "        Following the successful completion of preprocessing steps, create a grid search cv object that defines the model\n",
    "        for evaluation alongside a parameter grid and optimizing metric. This object will be fit on the preprocessed data in \n",
    "        order to find the model/hyperparameter combination that achieves the best performance on out of sample data given\n",
    "        our preprocessing, via the internal cross validation process, where best is defined as maximizing our metric \n",
    "        of choice. F1 score is our metric of choice in this case, so unless otherwise defined, 'f1' should be passed in for the\n",
    "        optimizing_metric value.\n",
    "        \n",
    "        The user will define an n_splits value which dictates the number of folds the training set will be split into,\n",
    "        and the number of iterations for our cross validation procedure. During each interation, the model will be fit\n",
    "        on n_splits - 1 folds and evaluated on the hold out fold. Overall, this will allow us to evaluate how well our\n",
    "        model and associated hyperparameter generalizes to out of sample data without incurring sampling bias as a \n",
    "        result of a poor train test split.\n",
    "        \n",
    "        Following fitting feature data on the grid search object, the grid search will autonomously identify a hyperparameter\n",
    "        combination that allows the model to generalize best to out of sample data according to our optimizing metric. At this \n",
    "        point, we can define what we would like returned.\n",
    "        \n",
    "        Readily available return options include:\n",
    "            \n",
    "            - returning transformed features\n",
    "            - returning the entire grid search object\n",
    "            - returning the best score of the grid search object\n",
    "            - returning the best estimator of the grid search object\n",
    "            - returning best parameters that optimize our metric given preprocessing steps and model\n",
    "        \n",
    "        One issue with grid search CV is it does not return out of sample predictions for our best model.\n",
    "        In order to circumvent this, we have a boolean command that lets the pipeline know to execute another \n",
    "        k fold cross validation procedure in order to store out of sample predictions for our best performing model. Note:\n",
    "        Due to discrepencies between random states and sampling, this might yield slightly different results to the \n",
    "        best score for our best estimator. We will include options that allow for returning out of sample predictions (0/1) \n",
    "        and out of sample predicted probabilities (P(Y = 1 | X))\n",
    "        \n",
    "        Finally, assuming we returned out of sample probabilities, we can also execute a threshold analysis to identify whether\n",
    "        a specific probability threshold allows us to achieve an improved out of sample metric score\n",
    "        '''\n",
    "        \n",
    "        features = X.copy() #copy feature matrix to avoid broadcasting\n",
    "        \n",
    "        #apply preprocessing steps as defined\n",
    "        if len(preprocessing) != 0:\n",
    "            for a,b in preprocessing:\n",
    "                if a == 'binarize':\n",
    "                    features = binarize_dataset(features,b[0],b[1])\n",
    "                elif a == 'crop':\n",
    "                    features = crop_dataset(features,b[0],b[1])\n",
    "                elif a == 'blur':\n",
    "                    features = process_dataset_blur(features.astype('float32'),b[0],b[1],b[2],b[3],b[4])\n",
    "                elif a == 'pool':\n",
    "                    features = do_pooling_dataset(features,b[0],b[1])\n",
    "        \n",
    "        #instantiate grid search object\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = param_grid, scoring = optimizing_metric,\n",
    "                                  cv = n_splits)\n",
    "        #Fit grid search on preprocessed features and labels to ID optimal model/hyperparameter combination that generalizes\n",
    "        #best to out of sample data\n",
    "        grid_search.fit(features,y)\n",
    "        \n",
    "        #With grid search fit, include initial return values in return dictionary\n",
    "        return_dict = {}\n",
    "        \n",
    "        if return_transformed_features: #return preprocessed features to avoid redundant preprocessing if those steps have\n",
    "            #been IDd as optimal\n",
    "            return_dict['features'] = features\n",
    "        if return_grid: #return entire grid search object\n",
    "            return_dict['grid_search'] = grid_search\n",
    "        if return_best_estimator: #return best estimator that has already been fit on all the feature data\n",
    "            return_dict['best_estimator'] = grid_search.best_estimator_\n",
    "        if return_best_params: #return optimal parameters that enable model to best generalize\n",
    "            return_dict['best_params'] = grid_search.best_params_\n",
    "        if return_score: #return best score\n",
    "            return_dict['best_score'] = grid_search.best_score_\n",
    "        \n",
    "        if return_oos_pred or return_oos_prob: #return out of sample prediction/predicted probabilities for our best model\n",
    "            preds = y.copy()\n",
    "            probs = y.copy()\n",
    "            kfold = KFold(n_splits=n_splits) #cv object\n",
    "            model_copy = clone(grid_search.best_estimator_) #create copy of best estimator\n",
    "            for train,test in kfold.split(features):\n",
    "                xtrain,xtest,ytrain,ytest = features.iloc[train],features.iloc[test],y.iloc[train],y.iloc[test]\n",
    "                model_copy.fit(xtrain,ytrain)\n",
    "                preds.iloc[test] = list(model_copy.predict(xtest))\n",
    "                probs.iloc[test] = list(model_copy.predict_proba(xtest)[:,1])\n",
    "            \n",
    "            #store out of sample binary predictions and out of sample probabilities\n",
    "            if return_oos_pred:\n",
    "                return_dict['oos_preds'] = preds\n",
    "            if return_oos_prob:\n",
    "                return_dict['oos_probs'] = probs\n",
    "                \n",
    "                #conduct threshold analysis to identify threshold that optimizes out of sample metric score\n",
    "                if return_threshold_analysis:\n",
    "                    best_thresh = 0.5\n",
    "                    best_score = f1_score(y,preds)\n",
    "                    best_preds = preds\n",
    "                    \n",
    "                    for num in np.linspace(0.01,0.99,99):\n",
    "                        threshold = num #create threshold\n",
    "                        mod_preds = np.array([1 if x >= threshold else 0 for x in list(probs)]) #map prob to prediction according to threshold\n",
    "                        score = f1_score(y,mod_preds) #evaluate out of sample f1 score given threshold and predicted probabilities\n",
    "                        if score > best_score: #if score using threshold is better than current best, update threshold, score,\n",
    "                            #and out of sample prediction values using that threshold\n",
    "                            best_thresh = threshold\n",
    "                            best_score = score\n",
    "                            best_preds = mod_preds\n",
    "                    \n",
    "                    return_dict['threshold_analysis'] = {'best_thresh':best_thresh,'best_score':best_score,'best_preds':best_preds}\n",
    "            \n",
    "        return return_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16badb",
   "metadata": {},
   "source": [
    "### Logistic Regression Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82668814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AGatt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\AGatt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\AGatt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\AGatt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\AGatt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\AGatt\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_search': GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "              param_grid={'C': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
       "                          'max_iter': [1000]},\n",
       "              scoring='f1'),\n",
       " 'best_estimator': LogisticRegression(C=1e-05, max_iter=1000),\n",
       " 'best_params': {'C': 1e-05, 'max_iter': 1000},\n",
       " 'best_score': 0.7588488817302667,\n",
       " 'oos_preds': 54      1\n",
       " 2602    0\n",
       " 3433    0\n",
       " 235     1\n",
       " 1806    1\n",
       "        ..\n",
       " 2421    1\n",
       " 3886    0\n",
       " 4482    0\n",
       " 3318    0\n",
       " 2158    1\n",
       " Name: label, Length: 500, dtype: uint8,\n",
       " 'oos_probs': 54      0.971404\n",
       " 2602    0.303823\n",
       " 3433    0.111128\n",
       " 235     0.555825\n",
       " 1806    0.834841\n",
       "           ...   \n",
       " 2421    0.999792\n",
       " 3886    0.433044\n",
       " 4482    0.201350\n",
       " 3318    0.002284\n",
       " 2158    0.787405\n",
       " Name: label, Length: 500, dtype: float64,\n",
       " 'threshold_analysis': {'best_thresh': 0.21000000000000002,\n",
       "  'best_score': 0.7873015873015873,\n",
       "  'best_preds': array([1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "         1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "         0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "         1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "         1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "         1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "         0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "         0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1])}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model_pipeline()\n",
    "test = test.evaluate(X.iloc[:500],\n",
    "                     y.iloc[:500],\n",
    "                     preprocessing = [('binarize',[True,0.3]),\n",
    "                                 ('crop',[(256,256),(256,256)]),\n",
    "                                 ('blur',['g',(256,256),(5,5),0,0]),\n",
    "                                 ('pool',[(2,2),np.max])],\n",
    "                     model = LogisticRegression(),\n",
    "                     param_grid={'C':[0.000001,0.00001,0.0001,0.001,0.01,0.1],\n",
    "                                'max_iter':[1000]},\n",
    "                     optimizing_metric='f1',\n",
    "                     n_splits=5,\n",
    "                     return_transformed_features = False, \n",
    "                     return_grid = True, \n",
    "                     return_score = True, \n",
    "                     return_best_estimator = True, \n",
    "                     return_best_params = True, \n",
    "                     return_oos_pred = True, \n",
    "                     return_oos_prob = True, \n",
    "                     return_threshold_analysis=True)\n",
    "                        \n",
    "test                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30523f9d",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b1fe33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_search': GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "              param_grid={'n_neighbors': [1, 3, 5, 7, 9, 11, 13]}, scoring='f1'),\n",
       " 'best_estimator': KNeighborsClassifier(n_neighbors=1),\n",
       " 'best_params': {'n_neighbors': 1},\n",
       " 'best_score': 0.7852945252945254,\n",
       " 'oos_preds': 54      0\n",
       " 2602    1\n",
       " 3433    0\n",
       " 235     0\n",
       " 1806    1\n",
       "        ..\n",
       " 2421    1\n",
       " 3886    0\n",
       " 4482    0\n",
       " 3318    0\n",
       " 2158    1\n",
       " Name: label, Length: 500, dtype: uint8,\n",
       " 'oos_probs': 54      0.0\n",
       " 2602    1.0\n",
       " 3433    0.0\n",
       " 235     0.0\n",
       " 1806    1.0\n",
       "        ... \n",
       " 2421    1.0\n",
       " 3886    0.0\n",
       " 4482    0.0\n",
       " 3318    0.0\n",
       " 2158    1.0\n",
       " Name: label, Length: 500, dtype: float64,\n",
       " 'threshold_analysis': {'best_thresh': 0.5,\n",
       "  'best_score': 0.777988614800759,\n",
       "  'best_preds': 54      0\n",
       "  2602    1\n",
       "  3433    0\n",
       "  235     0\n",
       "  1806    1\n",
       "         ..\n",
       "  2421    1\n",
       "  3886    0\n",
       "  4482    0\n",
       "  3318    0\n",
       "  2158    1\n",
       "  Name: label, Length: 500, dtype: uint8}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = model_pipeline()\n",
    "test_1 = test_1.evaluate(X.iloc[:500],\n",
    "                     y.iloc[:500],\n",
    "                     preprocessing = [('binarize',[True,0.3]),\n",
    "                                 ('crop',[(256,256),(256,256)]),\n",
    "                                 ('blur',['g',(256,256),(5,5),0,0]),\n",
    "                                 ('pool',[(2,2),np.max])],\n",
    "                     model = KNeighborsClassifier(),\n",
    "                     param_grid={'n_neighbors':[1,3,5,7,9,11,13]},\n",
    "                     optimizing_metric='f1',\n",
    "                     n_splits=5,\n",
    "                     return_transformed_features = False, \n",
    "                     return_grid = True, \n",
    "                     return_score = True, \n",
    "                     return_best_estimator = True, \n",
    "                     return_best_params = True, \n",
    "                     return_oos_pred = True, \n",
    "                     return_oos_prob = True, \n",
    "                     return_threshold_analysis=True)\n",
    "test_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529c47f",
   "metadata": {},
   "source": [
    "### Naive Bayes Example (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "496d0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = model_pipeline()\n",
    "test_2 = test_2.evaluate(X.iloc[:500],\n",
    "                     y.iloc[:500],\n",
    "                     preprocessing = [('binarize',[True,0.3]),\n",
    "                                 ('crop',[(256,256),(256,256)]),\n",
    "                                 ('blur',['g',(256,256),(5,5),0,0]),\n",
    "                                 ('pool',[(2,2),np.max])],\n",
    "                     model = GaussianNB(),\n",
    "                     param_grid={'var_smoothing':[0.000000001,0.00000001,0.0000001,0.000001,0.00001,0.0001,0.001,0.01,0.1,1]},\n",
    "                     optimizing_metric='f1',\n",
    "                     n_splits=5,\n",
    "                     return_transformed_features = False, \n",
    "                     return_grid = True, \n",
    "                     return_score = True, \n",
    "                     return_best_estimator = True, \n",
    "                     return_best_params = True, \n",
    "                     return_oos_pred = True, \n",
    "                     return_oos_prob = True, \n",
    "                     return_threshold_analysis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c8ac586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_search': GridSearchCV(cv=5, estimator=GaussianNB(),\n",
       "              param_grid={'var_smoothing': [1e-09, 1e-08, 1e-07, 1e-06, 1e-05,\n",
       "                                            0.0001, 0.001, 0.01, 0.1, 1]},\n",
       "              scoring='f1'),\n",
       " 'best_estimator': GaussianNB(),\n",
       " 'best_params': {'var_smoothing': 1e-09},\n",
       " 'best_score': 0.4394317962739015,\n",
       " 'oos_preds': 54      0\n",
       " 2602    0\n",
       " 3433    0\n",
       " 235     0\n",
       " 1806    1\n",
       "        ..\n",
       " 2421    1\n",
       " 3886    0\n",
       " 4482    0\n",
       " 3318    0\n",
       " 2158    0\n",
       " Name: label, Length: 500, dtype: uint8,\n",
       " 'oos_probs': 54      0.0\n",
       " 2602    0.0\n",
       " 3433    0.0\n",
       " 235     0.0\n",
       " 1806    1.0\n",
       "        ... \n",
       " 2421    1.0\n",
       " 3886    0.0\n",
       " 4482    0.0\n",
       " 3318    0.0\n",
       " 2158    0.0\n",
       " Name: label, Length: 500, dtype: float64,\n",
       " 'threshold_analysis': {'best_thresh': 0.5,\n",
       "  'best_score': 0.440318302387268,\n",
       "  'best_preds': 54      0\n",
       "  2602    0\n",
       "  3433    0\n",
       "  235     0\n",
       "  1806    1\n",
       "         ..\n",
       "  2421    1\n",
       "  3886    0\n",
       "  4482    0\n",
       "  3318    0\n",
       "  2158    0\n",
       "  Name: label, Length: 500, dtype: uint8}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6947bf8",
   "metadata": {},
   "source": [
    "### Random Forest Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15b7bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = model_pipeline()\n",
    "test_3 = test_3.evaluate(X.iloc[:500],\n",
    "                     y.iloc[:500],\n",
    "                     preprocessing = [('binarize',[True,0.3]),\n",
    "                                 ('crop',[(256,256),(256,256)]),\n",
    "                                 ('blur',['g',(256,256),(5,5),0,0]),\n",
    "                                 ('pool',[(2,2),np.max])],\n",
    "                     model = RandomForestClassifier(),\n",
    "                     param_grid={'n_estimators':[20,30,50,100,200,400],\n",
    "                                'min_samples_leaf':[3,5,7,9,11],\n",
    "                                'random_state':[50]},\n",
    "                     optimizing_metric='f1',\n",
    "                     n_splits=5,\n",
    "                     return_transformed_features = False, \n",
    "                     return_grid = True, \n",
    "                     return_score = True, \n",
    "                     return_best_estimator = True, \n",
    "                     return_best_params = True, \n",
    "                     return_oos_pred = True, \n",
    "                     return_oos_prob = True, \n",
    "                     return_threshold_analysis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3cb385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_search': GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "              param_grid={'min_samples_leaf': [3, 5, 7, 9, 11],\n",
       "                          'n_estimators': [20, 30, 50, 100, 200, 400],\n",
       "                          'random_state': [50]},\n",
       "              scoring='f1'),\n",
       " 'best_estimator': RandomForestClassifier(min_samples_leaf=3, n_estimators=400, random_state=50),\n",
       " 'best_params': {'min_samples_leaf': 3,\n",
       "  'n_estimators': 400,\n",
       "  'random_state': 50},\n",
       " 'best_score': 0.7997247828795128,\n",
       " 'oos_preds': 54      1\n",
       " 2602    0\n",
       " 3433    0\n",
       " 235     0\n",
       " 1806    1\n",
       "        ..\n",
       " 2421    1\n",
       " 3886    0\n",
       " 4482    0\n",
       " 3318    0\n",
       " 2158    1\n",
       " Name: label, Length: 500, dtype: uint8,\n",
       " 'oos_probs': 54      0.535632\n",
       " 2602    0.488565\n",
       " 3433    0.391306\n",
       " 235     0.435063\n",
       " 1806    0.799562\n",
       "           ...   \n",
       " 2421    0.850889\n",
       " 3886    0.392264\n",
       " 4482    0.347253\n",
       " 3318    0.435727\n",
       " 2158    0.707032\n",
       " Name: label, Length: 500, dtype: float64,\n",
       " 'threshold_analysis': {'best_thresh': 0.46,\n",
       "  'best_score': 0.8013468013468013,\n",
       "  'best_preds': array([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "         1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "         0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "         0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "         1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "         0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "         1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "         0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "         1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "         1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "         0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1])}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8b39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
