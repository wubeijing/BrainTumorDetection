{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8919e6",
   "metadata": {},
   "source": [
    "# Import Necessary Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e05a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PREPROCESSING FUNCTIONS FOR USE IN MODEL DEVELOPMENT, EVALUATION, AND PRODUCTION\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL as pil\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tempfile\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import skimage.filters\n",
    "import cv2\n",
    "import watermark\n",
    "import joblib\n",
    "import math\n",
    "from skimage.measure import block_reduce\n",
    "from image_preprocessing import standardize_image_dataset,resize_dataset,binarize_dataset,crop_dataset,process_dataset_blur,do_pooling_dataset\n",
    "from pipeline import model_pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42884540",
   "metadata": {},
   "source": [
    "# Read in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a317f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pickle.load(open('Amit/Labeled Data/train_data.pkl','rb'))\n",
    "train_x,train_y = all_data.iloc[:,:-1],all_data.iloc[:,-1]\n",
    "del all_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa029940",
   "metadata": {},
   "source": [
    "# Automated Model Development Pipeline\n",
    "\n",
    "Functional wrapper around model_pipeline class allowing for the automated identification of an optimal model and hyperparameter settings in conjunction with a greedy approach for identifying optimal preprocessing steps. \n",
    "\n",
    "The greedy approach is achieved by first identifying an optimal image size, or an image size that yields the best performing model without being too large to the point where it dramatically slows down training time and potentially reduces optimal model performance. Next, a specific preprocessing methodology is incorporated across a variety of preprocessing settings. For each of these settings, our image vectors / features are preprocessed according to these settings and an optimal model is identified. At the completion of evaluating a specific preprocessing methodology, if the optimal model identified is better than the previously identified optimal model trained on resized image data, the optimal model parameters are replaced. In addition, the features this model was trained on according to associated preprocessing settings are permanently applied to the features (Greedy). This process continues with other preprocessing methodologies as defined by the user, where at each step the pipeline identifies whether any additional preprocessing steps yield an improved model given previously incorporated preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0a2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_optimal_model_dev(X,y,model,param_grid,preprocessing_eval_order = ['bin/crop','blur','pool'],resize=True):\n",
    "    \n",
    "    #Store global values to capture optimal model/parameters, key performance metrics, and optimal preprocessing steps\n",
    "    best_feats = X.copy()\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "    best_probs = None\n",
    "    best_preds = None\n",
    "    best_thresh = None\n",
    "    best_score = 0\n",
    "    best_preprocess = '(Initial Standardization/Resizing to ' + str((int(np.sqrt(X.shape[1])),int(np.sqrt(X.shape[1])))) + ')'\n",
    "    # Initial Evaluation - Identify Optimal Size of Images, measured by performance of optimal model yielded by training on \n",
    "    #images of various\n",
    "    \n",
    "    if resize == True:\n",
    "\n",
    "        for img_size in [(2**num,2**num) for num in range(4,int(math.log2(np.sqrt(X.shape[1]))) + 1)]:\n",
    "\n",
    "            resize_results = model_pipeline().evaluate(resize_dataset(X,(int(np.sqrt(X.shape[1])),int(np.sqrt(X.shape[1]))),img_size),\n",
    "                                                       y,preprocessing=[],model=model,param_grid=param_grid,\n",
    "                                                       optimizing_metric='f1',n_splits=5,return_transformed_features=True,\n",
    "                                                       return_grid=True,return_score=True,return_best_estimator=True,\n",
    "                                                       return_best_params=True,return_oos_pred=True,return_oos_prob=True,\n",
    "                                                       return_threshold_analysis=True)\n",
    "            score = resize_results['threshold_analysis']['best_score'] #get f1 score of best performing model trained on images\n",
    "            #of specified size\n",
    "\n",
    "            if score - best_score > 0.001:\n",
    "\n",
    "            #Extract key results and the model for best performing model if model is at minimum > 0.01 in F1 score performance\n",
    "            # then previously identified optimal model\n",
    "                best_feats = resize_results['features']\n",
    "                best_model = resize_results['best_estimator']\n",
    "                best_params = resize_results['best_params']\n",
    "                best_probs = resize_results['oos_probs']\n",
    "                best_preds = resize_results['threshold_analysis']['best_preds']\n",
    "                best_thresh = resize_results['threshold_analysis']['best_thresh']\n",
    "                best_score = score\n",
    "                best_preprocess = '(Initial Standardization/Resizing to ' + str(img_size) + ')'\n",
    "                print('Better Model Identified by Resizing Images to ' + str(img_size) + ': ' + str(score))\n",
    "            else: \n",
    "                #break early if increasing image size does not yield a significantly better performing optimal model\n",
    "                break\n",
    "    \n",
    "    #detect size of images for binarization/cropping and blur preprocessing steps\n",
    "    image_size = int(np.sqrt(best_feats.shape[1]))\n",
    "    \n",
    "    binarization_crop_settings = [[('binarize',[True,0.3]),('crop',[(image_size,image_size),(image_size,image_size)])],\n",
    "                                         [('binarize',[False,0.05]),('crop',[(image_size,image_size),(image_size,image_size)])],\n",
    "                                         [('binarize',[False,0.1]),('crop',[(image_size,image_size),(image_size,image_size)])],\n",
    "                                         [('binarize',[False,0.15]),('crop',[(image_size,image_size),(image_size,image_size)])],\n",
    "                                         [('binarize',[False,0.2]),('crop',[(image_size,image_size),(image_size,image_size)])],\n",
    "                                         [('binarize',[False,0.3]),('crop',[(image_size,image_size),(image_size,image_size)])]]\n",
    "    \n",
    "    blur_settings = [[('blur',['g',(image_size,image_size),(3,3),0,0])],\n",
    "                     [('blur',['g',(image_size,image_size),(3,3),1,0])],\n",
    "                     [('blur',['g',(image_size,image_size),(3,3),0,1])],\n",
    "                     [('blur',['g',(image_size,image_size),(3,3),1,1])],\n",
    "                     [('blur',['g',(image_size,image_size),(3,3),2,2])],\n",
    "                     [('blur',['g',(image_size,image_size),(5,5),0,0])],\n",
    "                     [('blur',['g',(image_size,image_size),(5,5),1,0])],\n",
    "                     [('blur',['g',(image_size,image_size),(5,5),0,1])],\n",
    "                     [('blur',['g',(image_size,image_size),(5,5),1,1])],\n",
    "                     [('blur',['g',(image_size,image_size),(5,5),2,2])],\n",
    "                     [('blur',['b',(image_size,image_size),(3,3),0,0])],\n",
    "                     [('blur',['b',(image_size,image_size),(3,3),1,0])],\n",
    "                     [('blur',['b',(image_size,image_size),(3,3),0,1])],\n",
    "                     [('blur',['b',(image_size,image_size),(3,3),1,1])],\n",
    "                     [('blur',['b',(image_size,image_size),(3,3),2,2])],\n",
    "                     [('blur',['b',(image_size,image_size),(5,5),0,0])],\n",
    "                     [('blur',['b',(image_size,image_size),(5,5),1,0])],\n",
    "                     [('blur',['b',(image_size,image_size),(5,5),0,1])],\n",
    "                     [('blur',['b',(image_size,image_size),(5,5),1,1])],\n",
    "                     [('blur',['b',(image_size,image_size),(5,5),2,2])]]\n",
    "    \n",
    "    \n",
    "    #detect possible pooling settings dependent on image_size, controls possible pool sizes\n",
    "    pool_ranges = int(math.log2(image_size))\n",
    "    pool_settings = []\n",
    "    for num in range(1,pool_ranges):\n",
    "        pool_settings.append([('pool',[(2**num,2**num),np.max])])\n",
    "        pool_settings.append([('pool',[(2**num,2**num),np.mean])])\n",
    "    \n",
    "    for step in preprocessing_eval_order:\n",
    "        #Identify optimal model considering different image preprocessing settings to also identify\n",
    "        #optimal preprocessing settings\n",
    "        \n",
    "        #set settings we will evaluate depending on the user defined preprocessing evaluation order\n",
    "        if step == 'bin/crop':\n",
    "            settings = binarization_crop_settings\n",
    "        elif step == 'blur':\n",
    "            settings = blur_settings\n",
    "        elif step == 'pool':\n",
    "            settings = pool_settings\n",
    "        \n",
    "        best_setting = ''\n",
    "        best_setting_feats = None\n",
    "\n",
    "        #For each preprocessing setting, identify an optimal performing model trained on\n",
    "        #transformed features according to specified preprocessing. Compare each model to currently identified\n",
    "        #optimal model and replace if better model is found\n",
    "        for setting in settings:\n",
    "            if step == 'bin/crop' and int(np.sqrt(best_feats.shape[1])) != image_size: #if pooling was evaluated first and\n",
    "                #yielded a model better than base case, resulting data would have been resized so dimension settings for\n",
    "                #binarization, cropping will need to be adjusted\n",
    "                new_image_size = int(np.sqrt(best_feats.shape[1]))\n",
    "                setting[1][1][0] = (new_image_size,new_image_size)\n",
    "                setting[1][1][1] = (new_image_size,new_image_size)\n",
    "            elif step == 'blur' and int(np.sqrt(best_feats.shape[1])) != image_size: #same case as above but for blurring\n",
    "                new_image_size = int(np.sqrt(best_feats.shape[1]))\n",
    "                setting[0][1][1] = (new_image_size,new_image_size)\n",
    "            setting_case = model_pipeline().evaluate(best_feats,y,preprocessing=setting,model=model,param_grid=param_grid,\n",
    "                                                      optimizing_metric='f1',n_splits=5,return_transformed_features=True,\n",
    "                                                      return_grid=True,return_score=True,return_best_estimator=True,\n",
    "                                                      return_best_params=True,return_oos_pred=True,return_oos_prob=True,\n",
    "                                                      return_threshold_analysis=True)\n",
    "            score = setting_case['threshold_analysis']['best_score']#get F1 score of optimal model trained using preprocessed features\n",
    "            if score > best_score: #if score is better than current best score, update key results and model for optimal performing model\n",
    "                best_model = setting_case['best_estimator']\n",
    "                best_params = setting_case['best_params']\n",
    "                best_probs = setting_case['oos_probs']\n",
    "                best_preds = setting_case['threshold_analysis']['best_preds']\n",
    "                best_thresh = setting_case['threshold_analysis']['best_thresh']\n",
    "                best_score = score\n",
    "                best_setting_feats = setting_case['features']\n",
    "                if step == 'bin/crop':\n",
    "                    best_setting = '(Binarization, Automate Threshold = ' + str(setting[0][1][0]) + ', Threshold = ' + str(setting[0][1][1]) + ') (Crop, ' + str(setting[1][1][0]) + ', ' + str(setting[1][1][0]) + ')'\n",
    "                    print('Better Model Identified W/ Binarization/Cropping, Score = ' + str(score))\n",
    "                elif step == 'blur':\n",
    "                    best_setting = '(Blurring, Type = ' + str(setting[0][1][0]) + ', Dimension = ' + str(setting[0][1][1]) + ', Kernel = ' + str(setting[0][1][2]) + ', sigma_x = ' + str(setting[0][1][3]) + ', sigma_y = ' + str(setting[0][1][4]) + ')'\n",
    "                    print('Better Model Identified W/ Blurring, Score = ' + str(score))\n",
    "                elif step == 'pool':\n",
    "                    best_setting = '(Pool, pool_size = ' + str(setting[0][1][0]) + ', pooling_function = ' + str(setting[0][1][1]) + ')'\n",
    "                    print('Better Model Identified W/ Pooling, Score = ' + str(score))\n",
    "                    \n",
    "\n",
    "        #Update features and preprocessing string if incorporating specific preprocessing as part of image preprocessing pipeline yielded \n",
    "        #a better performing model. This ensures these steps do not need to be repeated when evaluating additional \n",
    "        #preprocessing steps\n",
    "        if best_setting != '':\n",
    "            best_feats = best_setting_feats\n",
    "            best_preprocess = best_preprocess + best_setting\n",
    "    \n",
    "    \n",
    "    #store and return optimal model, threshold, out of sample predictions, features the model was trained on, \n",
    "    #and optimal preprocessing steps identified via a greedy sequential decision process\n",
    "    return_dict = {}\n",
    "    return_dict['features'] = best_feats\n",
    "    return_dict['best_model'] = best_model\n",
    "    return_dict['best_params'] = best_params\n",
    "    return_dict['oos_probs'] = best_probs\n",
    "    return_dict['oos_preds'] = best_preds\n",
    "    return_dict['best_thresh'] = best_thresh\n",
    "    return_dict['best_score'] = best_score\n",
    "    return_dict['best_preprocess'] = best_preprocess\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fc81e",
   "metadata": {},
   "source": [
    "# Identify Optimal Random Forest Alongside Optimized Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64dedb2",
   "metadata": {},
   "source": [
    "[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]  \n",
    "1 = bin/crop  \n",
    "2 = blur  \n",
    "3 = pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b9e720",
   "metadata": {},
   "source": [
    "### Test 1: Identify optimal Random Forest while sequentially identifying optimal settings for bin/crop, blur, and pooling [3,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d54119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better Model Identified by Resizing Images to (16, 16): 0.9550153674210674\n",
      "Better Model Identified by Resizing Images to (32, 32): 0.9597315436241611\n",
      "Better Model Identified W/ Pooling, Score = 0.9607132906101978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features':       0    1    2    3    4    5    6    7    8    9    ...  246  247  248  \\\n",
       " 54      0    1    1    1    1    4   60   65   73   19  ...  116  157  140   \n",
       " 2602    3    3    3    3    3    3   58   70   54   55  ...   92   97  105   \n",
       " 3433    0    1    2    2    2    2    2    2    2    2  ...  191  211  211   \n",
       " 235     0   24   60   46   52   84   81   63   64   84  ...   64   89  116   \n",
       " 1806    0    3    3    3    3    3    3    3    3    3  ...  137  117  115   \n",
       " ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 3330    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       " 70     52    4    5    5    5    5    6    9   10    6  ...   21   22   26   \n",
       " 132     0    0    0    0    0   20   48   62   64   55  ...   67   77   80   \n",
       " 2014    6    6    6    6    4    4    4    4    4    4  ...  113  138  103   \n",
       " 1931    1    1    1    1    1  135  190  188  201  191  ...  193  163  179   \n",
       " \n",
       "       249  250  251  252  253  254  255  \n",
       " 54     80    1    1    1    1    1    0  \n",
       " 2602   77   86   11    3    3    3    3  \n",
       " 3433  193   99    2    2    2    1    0  \n",
       " 235    81   75   46   48   60   26    0  \n",
       " 1806  133  130   78  187   16    5    0  \n",
       " ...   ...  ...  ...  ...  ...  ...  ...  \n",
       " 3330    0    0    0    0    0    0    0  \n",
       " 70     21   22   21   20   20   20   19  \n",
       " 132    72   46    0    0    0    0    0  \n",
       " 2014  158  163  163  111   97    6    6  \n",
       " 1931  163  159  188   48    1    1    1  \n",
       " \n",
       " [3220 rows x 256 columns],\n",
       " 'best_model': RandomForestClassifier(min_samples_leaf=3, n_estimators=500, random_state=50),\n",
       " 'best_params': {'min_samples_leaf': 3,\n",
       "  'n_estimators': 500,\n",
       "  'random_state': 50},\n",
       " 'oos_probs': 54      0.861790\n",
       " 2602    0.455583\n",
       " 3433    0.081655\n",
       " 235     0.750577\n",
       " 1806    0.935848\n",
       "           ...   \n",
       " 3330    0.040563\n",
       " 70      0.645594\n",
       " 132     0.850013\n",
       " 2014    0.915890\n",
       " 1931    0.861360\n",
       " Name: label, Length: 3220, dtype: float64,\n",
       " 'oos_preds': array([1, 0, 0, ..., 1, 1, 1]),\n",
       " 'best_thresh': 0.55,\n",
       " 'best_score': 0.9607132906101978,\n",
       " 'best_preprocess': '(Initial Standardization/Resizing to (32, 32))(Pool, pool_size = (2, 2), pooling_function = <function amax at 0x0000029964896E50>)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = automate_optimal_model_dev(X = resize_dataset(train_x,(256,256),(32,32)),y = train_y,\n",
    "                                    model = RandomForestClassifier(),\n",
    "                                    param_grid={'n_estimators':[100,200,500],\n",
    "                                                'min_samples_leaf':[3,5,7,9],\n",
    "                                                'random_state':[50]},\n",
    "                                    preprocessing_eval_order = ['pool','blur','bin/crop'])\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1816e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_1,open('Partition Based Model Results/rf1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7364e1",
   "metadata": {},
   "source": [
    "### Test 2: Identify optimal Random Forest while sequentially identifying optimal settings for bin/crop, blur, and pooling [3,1,2], Test 1 yielded that resize value of 32x32 is optimal and pooling can be optimized after with a 2x2 np.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ce9d6",
   "metadata": {},
   "source": [
    "test_2 = automate_optimal_model_dev(X = do_pooling_dataset(resize_dataset(train_x,(256,256),(32,32)),(2,2),np.mean),y = train_y,\n",
    "                                    model = RandomForestClassifier(),\n",
    "                                    param_grid={'n_estimators':[100,200,500],\n",
    "                                                'min_samples_leaf':[3,5,7,9],\n",
    "                                                'random_state':[50]},\n",
    "                                    preprocessing_eval_order = ['bin/crop','blur'],resize=False)\n",
    "test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4b56b",
   "metadata": {},
   "source": [
    "pickle.dump(test_2,open('Partition Based Model Results/rf2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee3a510",
   "metadata": {},
   "source": [
    "### Test 3: Identify optimal Random Forest while sequentially identifying optimal settings for bin/crop, blur, and pooling [2,1,3], test 1 yielded resize of 32x32 as optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96ba0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better Model Identified by Resizing Images to (16, 16): 0.9550153674210674\n",
      "Better Model Identified by Resizing Images to (32, 32): 0.9597315436241611\n",
      "Better Model Identified W/ Blurring, Score = 0.9611486486486487\n",
      "Better Model Identified W/ Blurring, Score = 0.9612141652613828\n",
      "Better Model Identified W/ Blurring, Score = 0.9614843969637336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features':          pixel0     pixel1    pixel2     pixel3     pixel4     pixel5  \\\n",
       " 54     0.000000   0.000000  0.319168   0.680832   1.000000   1.000000   \n",
       " 2602   2.100062   2.015369  2.319168   2.550031   2.769137   2.869199   \n",
       " 3433   0.000000   0.000000  0.319168   0.796264   1.449969   1.680832   \n",
       " 235    0.000000   0.000000  6.030138  21.093441  30.528057  33.094044   \n",
       " 1806   0.000000   0.726640  1.550031   2.276671   2.276671   2.507534   \n",
       " ...         ...        ...       ...        ...        ...        ...   \n",
       " 3330   0.000000   0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       " 70    18.152546  17.180805  2.477096   3.842072   4.072935   4.392103   \n",
       " 132    0.000000   0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       " 2014   4.553342   4.553342  4.553342   4.553342   4.553342   4.784205   \n",
       " 1931   1.000000   1.000000  1.000000   1.000000   1.000000   1.000000   \n",
       " \n",
       "          pixel6     pixel7     pixel8     pixel9  ...   pixel1014   pixel1015  \\\n",
       " 54     1.000000   1.000000   1.000000   0.796264  ...    0.796264    1.000000   \n",
       " 2602   2.769137   2.869199   2.884568   3.000000  ...   15.875785    4.629889   \n",
       " 3433   1.869199   1.769137   1.550031   1.522904  ...    6.881220    1.246233   \n",
       " 235   27.949997  29.960232  36.785107  47.963863  ...   43.836670   34.815845   \n",
       " 1806   2.769137   2.769137   2.738398   2.769137  ...   81.499634   97.036423   \n",
       " ...         ...        ...        ...        ...  ...         ...         ...   \n",
       " 3330   0.000000   0.000000   0.000000   0.000000  ...    0.000000    0.000000   \n",
       " 70     4.522904   4.638336   4.638336   4.638336  ...   11.105800   10.540399   \n",
       " 132    0.000000   0.000000   0.000000   0.407472  ...    2.444834    0.000000   \n",
       " 2014   4.407472   3.915006   3.276671   3.276671  ...  137.752228  122.872192   \n",
       " 1931   1.000000   0.796264   0.565401   7.376997  ...  115.742584   83.403809   \n",
       " \n",
       "        pixel1016   pixel1017  pixel1018  pixel1019  pixel1020  pixel1021  \\\n",
       " 54      1.000000    1.000000   1.000000   1.000000   0.680832   0.319168   \n",
       " 2602    3.000000    3.000000   3.000000   2.884568   2.753767   2.638335   \n",
       " 3433    1.796264    1.884568   1.550031   1.203736   0.680832   0.319168   \n",
       " 235    29.968678   29.372837  34.048233  33.230881  23.432814   8.094625   \n",
       " 1806  132.549713  111.793350  56.186150   5.563576   3.145870   2.419230   \n",
       " ...          ...         ...        ...        ...        ...        ...   \n",
       " 3330    0.000000    0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       " 70      9.990368    9.786632   9.671200   9.540399   9.540399   9.352032   \n",
       " 132     0.000000    0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       " 2014  104.567780   93.111481  62.216133  32.012306   5.130801   5.507534   \n",
       " 1931   39.923660   10.025567   0.565401   0.796264   1.000000   1.000000   \n",
       " \n",
       "       pixel1022  pixel1023  \n",
       " 54     0.000000   0.000000  \n",
       " 2602   2.319168   2.276671  \n",
       " 3433   0.000000   0.000000  \n",
       " 235    0.000000   0.000000  \n",
       " 1806   1.134112   0.000000  \n",
       " ...         ...        ...  \n",
       " 3330   0.000000   0.000000  \n",
       " 70     9.105800   8.786632  \n",
       " 132    0.000000   0.000000  \n",
       " 2014   5.276671   5.276671  \n",
       " 1931   1.000000   1.000000  \n",
       " \n",
       " [3220 rows x 1024 columns],\n",
       " 'best_model': RandomForestClassifier(min_samples_leaf=3, n_estimators=500, random_state=50),\n",
       " 'best_params': {'min_samples_leaf': 3,\n",
       "  'n_estimators': 500,\n",
       "  'random_state': 50},\n",
       " 'oos_probs': 54      0.929998\n",
       " 2602    0.402724\n",
       " 3433    0.127881\n",
       " 235     0.806454\n",
       " 1806    0.956779\n",
       "           ...   \n",
       " 3330    0.036048\n",
       " 70      0.610914\n",
       " 132     0.774721\n",
       " 2014    0.935370\n",
       " 1931    0.923944\n",
       " Name: label, Length: 3220, dtype: float64,\n",
       " 'oos_preds': array([1, 0, 0, ..., 1, 1, 1]),\n",
       " 'best_thresh': 0.56,\n",
       " 'best_score': 0.9614843969637336,\n",
       " 'best_preprocess': '(Initial Standardization/Resizing to (32, 32))(Blurring, Type = g, Dimension = (32, 32), Kernel = (3, 3), sigma_x = 2, sigma_y = 2)'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3 = automate_optimal_model_dev(X = resize_dataset(train_x,(256,256),(32,32)),y = train_y,\n",
    "                                    model = RandomForestClassifier(),\n",
    "                                    param_grid={'n_estimators':[100,200,500],\n",
    "                                                'min_samples_leaf':[3,5,7,9],\n",
    "                                                'random_state':[50]},\n",
    "                                    preprocessing_eval_order = ['blur','bin/crop','pool'],resize=True)\n",
    "test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73dc3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_3,open('Partition Based Model Results/rf2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b3787",
   "metadata": {},
   "source": [
    "### Test 4: Identify optimal Random Forest while sequentially identifying optimal settings for bin/crop, blur, and pooling [1,2,3], test 1 yielded resize of 32x32 as optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84070844",
   "metadata": {},
   "source": [
    "test_4 = automate_optimal_model_dev(X = resize_dataset(train_x,(256,256),(32,32)),y = train_y,\n",
    "                                    model = RandomForestClassifier(),\n",
    "                                    param_grid={'n_estimators':[100,200,500],\n",
    "                                                'min_samples_leaf':[3,5,7,9],\n",
    "                                                'random_state':[50]},\n",
    "                                    preprocessing_eval_order = ['bin/crop','blur','pool'],resize=False)\n",
    "test_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358a7c3",
   "metadata": {},
   "source": [
    "### Test 5: Identify optimal Random Forest while sequentially identifying optimal settings for bin/crop, blur, and pooling [1,3,2], test 1 yielded resize of 32x32 as optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b40445",
   "metadata": {},
   "source": [
    "test_5 = automate_optimal_model_dev(X = resize_dataset(train_x,(256,256),(32,32)),y = train_y,\n",
    "                                    model = RandomForestClassifier(),\n",
    "                                    param_grid={'n_estimators':[100,200,500],\n",
    "                                                'min_samples_leaf':[3,5,7,9],\n",
    "                                                'random_state':[50]},\n",
    "                                    preprocessing_eval_order = ['bin/crop','pool','blur'],resize=False)\n",
    "test_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1a958",
   "metadata": {},
   "source": [
    "### Test 6: Identify optimal Random Forest while sequentially identifying optimal settings for bin/crop, blur, and pooling [2,3,1], test 1 yielded resize of 32x32 as optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11db8c3",
   "metadata": {},
   "source": [
    "test_6 = automate_optimal_model_dev(X = resize_dataset(train_x,(256,256),(32,32)),y = train_y,\n",
    "                                    model = RandomForestClassifier(),\n",
    "                                    param_grid={'n_estimators':[100,200,500],\n",
    "                                                'min_samples_leaf':[3,5,7,9],\n",
    "                                                'random_state':[50]},\n",
    "                                    preprocessing_eval_order = ['blur','pool','bin/crop'],resize=True)\n",
    "test_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41140f0",
   "metadata": {},
   "source": [
    "pickle.dump(test_6,open('Partition Based Model Results/rf3.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
