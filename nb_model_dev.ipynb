{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PREPROCESSING FUNCTIONS FOR USE IN MODEL DEVELOPMENT, EVALUATION, AND PRODUCTION\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL as pil\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tempfile\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import skimage.filters\n",
    "import cv2\n",
    "import watermark\n",
    "import joblib\n",
    "import math\n",
    "from skimage.measure import block_reduce\n",
    "from image_preprocessing import standardize_image_dataset,resize_dataset,binarize_dataset,crop_dataset,process_dataset_blur,do_pooling_dataset\n",
    "from pipeline import model_pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run standardize_image_dataset from image_preprocessing.py to standardize full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize_image_dataset(all_pic_files,newdim=(256,256))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run cells from Split Labeled Data.ipynb to split data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open('Amit/Labeled Data/labeled_data.pkl','rb'))\n",
    "# X,y = all_data.iloc[:,:-1], all_data['label']\n",
    "# xtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=50)\n",
    "# pickle.dump(pd.concat([xtrain,ytrain],axis=1),open('Amit/Labeled Data/train_data.pkl','wb'))\n",
    "# pickle.dump(pd.concat([xtest,ytest],axis=1),open('Amit/Labeled Data/training_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read in Training Data and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pickle.load(open('Amit/Labeled Data/train_data.pkl','rb'))\n",
    "train_x,train_y = all_data.iloc[:,:-1],all_data.iloc[:,-1]\n",
    "del all_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/neilbhatia/GitHub/w207_final_project_LOCAL/Amit/Labeled Data/test_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22072/3208754891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test_data = pickle.load(open('Amit/Labeled Data/test_data.pkl','rb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Annoying error with pickling. Comment the line below and uncomment the line above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/neilbhatia/GitHub/w207_final_project_LOCAL/Amit/Labeled Data/test_data.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/neilbhatia/GitHub/w207_final_project_LOCAL/Amit/Labeled Data/test_data.pkl'"
     ]
    }
   ],
   "source": [
    "# test_data = pickle.load(open('Amit/Labeled Data/test_data.pkl','rb'))\n",
    "# Annoying error with pickling. Comment the line below and uncomment the line above.\n",
    "test_data = pickle.load(open('/Users/neilbhatia/GitHub/w207_final_project_LOCAL/Amit/Labeled Data/test_data.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Resize Vectorized Image Dataset - Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = resize_dataset(train_x,(256,256),(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = resize_dataset(test_x,(256,256),(128,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing for model testing and development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automate_optimal_model_dev import automate_optimal_model_dev\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Model Test 1: Identify optimal Bernoulli Model while sequentially identifying optimal settings for bin/crop, blur, and pooling [3,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5192/3353901062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m test_1_bernoulli = automate_optimal_model_dev(X = train_x,y = train_y,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                     \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                     preprocessing_eval_order = ['pool','blur','bin/crop'])\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitHub\\w207_final_project\\automate_optimal_model_dev.py\u001b[0m in \u001b[0;36mautomate_optimal_model_dev\u001b[1;34m(X, y, model, param_grid, preprocessing_eval_order, resize)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             resize_results = model_pipeline().evaluate(resize_dataset(X,(int(np.sqrt(X.shape[1])),int(np.sqrt(X.shape[1]))),img_size),\n\u001b[0m\u001b[0;32m     50\u001b[0m                                                        \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                                                        \u001b[0moptimizing_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_transformed_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitHub\\w207_final_project\\image_preprocessing.py\u001b[0m in \u001b[0;36mresize_dataset\u001b[1;34m(image_dataset, old_dim, new_dim)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mvectorized_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#resize every vectorized image to new dimensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0mvectorized_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresize_vector_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mold_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m     \u001b[1;31m#return vectorized images in a dataframe format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorized_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'pixel'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\GitHub\\w207_final_project\\image_preprocessing.py\u001b[0m in \u001b[0;36mresize_vector_image\u001b[1;34m(img_vec, old_dim, new_dim)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m#save as image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m     \u001b[1;31m#open as greyscale image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\w207_env\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimsave\u001b[1;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2143\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2144\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\w207_env\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1639\u001b[0m             \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1641\u001b[1;33m             \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1642\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpil_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1643\u001b[0m             \u001b[0mpil_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\w207_env\\lib\\site-packages\\matplotlib\\cm.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(self, x, alpha, bytes, norm)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\w207_env\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, alpha, bytes)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mxa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"f\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 \u001b[0mxa\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m                 \u001b[1;31m# Negative values are out of range, but astype(int) would\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;31m# truncate them towards zero.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_1_bernoulli = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['pool','blur','bin/crop'])\n",
    "\n",
    "with open('nb_model_results/nb_bernoilli_model_test1.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_1_bernoulli, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n",
    "test_2_bernoulli = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['pool','bin/crop','blur'])\n",
    "\n",
    "with open('nb_model_results/nb_bernoulli_model_test2.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_2_bernoulli, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_3_bernoulli = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['blur','bin/crop','pool'])\n",
    "\n",
    "with open('nb_model_results/nb_bernoulli_model_test3.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_3_bernoulli, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_4_bernoulli = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['bin/crop','blur','pool'])\n",
    "\n",
    "with open('nb_model_results/nb_bernoulli_model_test4.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_4_bernoulli, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_5_bernoulli = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['bin/crop','pool','blur'])\n",
    "\n",
    "with open('nb_model_results/nb_bernoulli_model_test5.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_5_bernoulli, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_6_bernoulli = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['blur','pool','bin/crop'])\n",
    "\n",
    "with open('nb_model_results/nb_bernoulli_model_test6.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_6_bernoulli, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Model Test 1: Identify optimal Gaussian Model while sequentially identifying optimal settings for bin/crop, blur, and pooling [3,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Case (No Preprocessing Best Score): 0.4498242873877392\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.46515209857527917\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.5199576121511833\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.5849546044098574\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7443428021184401\n"
     ]
    }
   ],
   "source": [
    "# alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "test_1_gaussian = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = GaussianNB(),\n",
    "                                    param_grid={'var_smoothing': np.linspace(0.00000000001,1,100)},\n",
    "                                    preprocessing_eval_order = ['pool','blur','bin/crop'])\n",
    "\n",
    "\n",
    "\n",
    "with open('nb_model_results/nb_gaussian_model_test1.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_1_gaussian, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Case (No Preprocessing Best Score): 0.4498242873877392\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.46515209857527917\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.5199576121511833\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.5849546044098574\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7443428021184401\n",
      "Base Case (No Preprocessing Best Score): 0.4498242873877392\n",
      "Better Model Identified W/ Blurring, Score = 0.46636085626911317\n",
      "Better Model Identified W/ Blurring, Score = 0.46671767406273906\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.719572001783326\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7197505197505197\n",
      "Base Case (No Preprocessing Best Score): 0.4498242873877392\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7091518926689027\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7139567019806541\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7377994676131322\n",
      "Base Case (No Preprocessing Best Score): 0.4498242873877392\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7091518926689027\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7139567019806541\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7377994676131322\n",
      "Better Model Identified W/ Blurring, Score = 0.7380627557980901\n",
      "Base Case (No Preprocessing Best Score): 0.4498242873877392\n",
      "Better Model Identified W/ Blurring, Score = 0.46636085626911317\n",
      "Better Model Identified W/ Blurring, Score = 0.46671767406273906\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.4680199157410954\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.47829286239882257\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.5600794438927507\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.6935991605456453\n",
      "Better Model Identified W/ Binarization/Cropping, Score = 0.7228260869565217\n"
     ]
    }
   ],
   "source": [
    "test_2_gaussian = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = GaussianNB(),\n",
    "                                    param_grid={'var_smoothing': np.linspace(0.00000000001,1,100)},\n",
    "                                    preprocessing_eval_order = ['pool','bin/crop','blur'])\n",
    "\n",
    "\n",
    "\n",
    "with open('nb_model_results/nb_gaussian_model_test2.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_2_gaussian, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_3_gaussian = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = GaussianNB(),\n",
    "                                    param_grid={'var_smoothing': np.linspace(0.00000000001,1,100)},\n",
    "                                    preprocessing_eval_order = ['blur','bin/crop','pool'])\n",
    "\n",
    "\n",
    "\n",
    "with open('nb_model_results/nb_gaussian_model_test3.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_3_gaussian, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_4_gaussian = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = GaussianNB(),\n",
    "                                    param_grid={'var_smoothing': np.linspace(0.00000000001,1,100)},\n",
    "                                    preprocessing_eval_order = ['bin/crop','blur','pool'])\n",
    "\n",
    "\n",
    "\n",
    "with open('nb_model_results/nb_gaussian_model_test4.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_4_gaussian, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_5_gaussian = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = GaussianNB(),\n",
    "                                    param_grid={'var_smoothing': np.linspace(0.00000000001,1,100)},\n",
    "                                    preprocessing_eval_order = ['bin/crop','pool','blur'])\n",
    "\n",
    "\n",
    "\n",
    "with open('nb_model_results/nb_gaussian_model_test5.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_5_gaussian, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "test_6_gaussian = automate_optimal_model_dev(X = train_x,y = train_y,\n",
    "                                    model = GaussianNB(),\n",
    "                                    param_grid={'var_smoothing': np.linspace(0.00000000001,1,100)},\n",
    "                                    preprocessing_eval_order = ['blur','pool','bin/crop'])\n",
    "\n",
    "\n",
    "\n",
    "with open('nb_model_results/nb_gaussian_model_test6.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_6_gaussian, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli_model_results_test1 = pickle.load(open('nb_model_results/nb_bernoulli_model_test1.pickle','rb'))\n",
    "bernoulli_model_results_test2 = pickle.load(open('nb_model_results/nb_bernoulli_model_test2.pickle','rb'))\n",
    "bernoulli_model_results_test3 = pickle.load(open('nb_model_results/nb_bernoulli_model_test3.pickle','rb'))\n",
    "bernoulli_model_results_test4 = pickle.load(open('nb_model_results/nb_bernoulli_model_test4.pickle','rb'))\n",
    "bernoulli_model_results_test5 = pickle.load(open('nb_model_results/nb_bernoulli_model_test5.pickle','rb'))\n",
    "bernoulli_model_results_test6 = pickle.load(open('nb_model_results/nb_bernoulli_model_test6.pickle','rb'))\n",
    "\n",
    "bernoulli_model_results_list = [bernoulli_model_results_test1,bernoulli_model_results_test2,bernoulli_model_results_test3,bernoulli_model_results_test4,bernoulli_model_results_test5,bernoulli_model_results_test6]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_model_results_test1 = pickle.load(open('nb_model_results/nb_gaussian_model_test1.pickle','rb'))\n",
    "gaussian_model_results_test2 = pickle.load(open('nb_model_results/nb_gaussian_model_test2.pickle','rb'))\n",
    "gaussian_model_results_test3 = pickle.load(open('nb_model_results/nb_gaussian_model_test3.pickle','rb'))\n",
    "gaussian_model_results_test4 = pickle.load(open('nb_model_results/nb_gaussian_model_test4.pickle','rb'))\n",
    "gaussian_model_results_test5 = pickle.load(open('nb_model_results/nb_gaussian_model_test5.pickle','rb'))\n",
    "gaussian_model_results_test6 = pickle.load(open('nb_model_results/nb_gaussian_model_test6.pickle','rb'))\n",
    "\n",
    "gaussian_model_results_list = [gaussian_model_results_test1,gaussian_model_results_test2,gaussian_model_results_test3,gaussian_model_results_test4,gaussian_model_results_test5,gaussian_model_results_test6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 ------------------------------------\n",
      "Best Threshold: 0.01\n",
      "F1 Score 0.7340137471360132\n",
      "BernoulliNB(alpha=10.0) : (Initial Standardization/Resizing)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>)(Blurring, Type = g, Dimension = (16, 16), Kernel = (5, 5), sigma_x = 0, sigma_y = 0) 0.01\n",
      "Model 2 ------------------------------------\n",
      "Best Threshold: 0.01\n",
      "F1 Score 0.7340137471360132\n",
      "BernoulliNB(alpha=10.0) : (Initial Standardization/Resizing)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>)(Blurring, Type = g, Dimension = (16, 16), Kernel = (5, 5), sigma_x = 0, sigma_y = 0) 0.01\n",
      "Model 3 ------------------------------------\n",
      "Best Threshold: 0.11\n",
      "F1 Score 0.7346197502837684\n",
      "BernoulliNB(alpha=10.0) : (Initial Standardization/Resizing)(Blurring, Type = b, Dimension = (128, 128), Kernel = (3, 3), sigma_x = 0, sigma_y = 0)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>) 0.11\n",
      "Model 4 ------------------------------------\n",
      "Best Threshold: 0.11\n",
      "F1 Score 0.7346197502837684\n",
      "BernoulliNB(alpha=10.0) : (Initial Standardization/Resizing)(Blurring, Type = b, Dimension = (128, 128), Kernel = (3, 3), sigma_x = 0, sigma_y = 0)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>) 0.11\n",
      "Model 5 ------------------------------------\n",
      "Best Threshold: 0.01\n",
      "F1 Score 0.7340137471360132\n",
      "BernoulliNB(alpha=10.0) : (Initial Standardization/Resizing)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>)(Blurring, Type = g, Dimension = (16, 16), Kernel = (5, 5), sigma_x = 0, sigma_y = 0) 0.01\n",
      "Model 6 ------------------------------------\n",
      "Best Threshold: 0.11\n",
      "F1 Score 0.7346197502837684\n",
      "BernoulliNB(alpha=10.0) : (Initial Standardization/Resizing)(Blurring, Type = b, Dimension = (128, 128), Kernel = (3, 3), sigma_x = 0, sigma_y = 0)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>) 0.11\n",
      "The top model for bernoulli is: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,bernoulli_results in enumerate(bernoulli_model_results_list):\n",
    "    print('Model',i+1,'------------------------------------')\n",
    "    print(\"Best Threshold:\",bernoulli_results['best_thresh'])\n",
    "    print(\"F1 Score\", bernoulli_results['best_score'])\n",
    "    print(bernoulli_results['best_model'],\":\",bernoulli_results['best_preprocess'], bernoulli_results['best_thresh'])\n",
    "\n",
    "\n",
    "bernoulli_model_f1_scores_list = [model['best_score'] for model in bernoulli_model_results_list]\n",
    "\n",
    "top_bernoulli_model_number = bernoulli_model_f1_scores_list.index(max(bernoulli_model_f1_scores_list))+1\n",
    "\n",
    "print(\"The top model for bernoulli is:\",top_bernoulli_model_number)\n",
    "\n",
    "\n",
    "\n",
    "with open('nb_model_results/top_bernoulli_model.pickle', 'wb') as handle:\n",
    "    pickle.dump(bernoulli_model_results_test3, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#Picking the best model based on score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 ------------------------------------\n",
      "Best Threshold: 0.060000000000000005\n",
      "F1 Score 0.7443428021184401\n",
      "GaussianNB(var_smoothing=1e-11) : (Initial Standardization/Resizing)(Pool, pool_size = (16, 16), pooling_function = <function amax at 0x11194eca0>) 0.060000000000000005\n",
      "Model 2 ------------------------------------\n",
      "Best Threshold: 0.060000000000000005\n",
      "F1 Score 0.7443428021184401\n",
      "GaussianNB(var_smoothing=1e-11) : (Initial Standardization/Resizing)(Pool, pool_size = (16, 16), pooling_function = <function amax at 0x11194eca0>) 0.060000000000000005\n",
      "Model 3 ------------------------------------\n",
      "Best Threshold: 0.13\n",
      "F1 Score 0.7197505197505197\n",
      "GaussianNB(var_smoothing=0.8787878787890909) : (Initial Standardization/Resizing)(Blurring, Type = g, Dimension = (128, 128), Kernel = (3, 3), sigma_x = 1, sigma_y = 0)(Binarization, Automate Threshold = True, Threshold = 0.3) (Crop, (128, 128), (128, 128))(Pool, pool_size = (8, 8), pooling_function = <function mean at 0x111956a60>) 0.13\n",
      "Model 4 ------------------------------------\n",
      "Best Threshold: 0.01\n",
      "F1 Score 0.7377994676131322\n",
      "GaussianNB(var_smoothing=1.0) : (Initial Standardization/Resizing)(Binarization, Automate Threshold = True, Threshold = 0.3) (Crop, (128, 128), (128, 128))(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>) 0.01\n",
      "Model 5 ------------------------------------\n",
      "Best Threshold: 0.09\n",
      "F1 Score 0.7380627557980901\n",
      "GaussianNB(var_smoothing=0.9494949494954545) : (Initial Standardization/Resizing)(Binarization, Automate Threshold = True, Threshold = 0.3) (Crop, (128, 128), (128, 128))(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>)(Blurring, Type = g, Dimension = (16, 16), Kernel = (5, 5), sigma_x = 0, sigma_y = 0) 0.09\n",
      "Model 6 ------------------------------------\n",
      "Best Threshold: 0.02\n",
      "F1 Score 0.7228260869565217\n",
      "GaussianNB(var_smoothing=0.060606060615454545) : (Initial Standardization/Resizing)(Blurring, Type = g, Dimension = (128, 128), Kernel = (3, 3), sigma_x = 1, sigma_y = 0)(Pool, pool_size = (32, 32), pooling_function = <function amax at 0x11194eca0>) 0.02\n",
      "The top model for gaussian is: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,gaussian_results in enumerate(gaussian_model_results_list):\n",
    "    print('Model',i+1,'------------------------------------')\n",
    "    print(\"Best Threshold:\",gaussian_results['best_thresh'])\n",
    "    print(\"F1 Score\", gaussian_results['best_score'])\n",
    "    print(gaussian_results['best_model'],\":\",gaussian_results['best_preprocess'], gaussian_results['best_thresh'])\n",
    "\n",
    "\n",
    "gaussian_model_f1_scores_list = [model['best_score'] for model in gaussian_model_results_list]\n",
    "\n",
    "top_gaussian_model_number = gaussian_model_f1_scores_list.index(max(gaussian_model_f1_scores_list))+1\n",
    "\n",
    "print(\"The top model for gaussian is:\",top_gaussian_model_number)\n",
    "\n",
    "with open('nb_model_results/top_gaussian_model.pickle', 'wb') as handle:\n",
    "    pickle.dump(gaussian_model_results_test1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#Picking the best model based on score \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The top Gaussian Model was the 1st one, and the top Bernoulli Model was the 3rd one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bernoulli_model_results_test3\n",
    "# gaussian_model_results_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Gaussian Model Score: 0.7443428021184401\n",
      "Top Bernoulli Model Score: 0.7346197502837684\n",
      "Gaussian is a slightly better model\n"
     ]
    }
   ],
   "source": [
    "print(\"Top Gaussian Model Score:\",gaussian_model_results_test1['best_score'])\n",
    "\n",
    "print(\"Top Bernoulli Model Score:\",bernoulli_model_results_test3['best_score'])\n",
    "\n",
    "print(\"Gaussian is a slightly better model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Initial Standardization/Resizing)(Blurring, Type = b, Dimension = (128, 128), Kernel = (3, 3), sigma_x = 0, sigma_y = 0)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>)\n",
      "(Initial Standardization/Resizing)(Pool, pool_size = (16, 16), pooling_function = <function amax at 0x11194eca0>)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "print(bernoulli_model_results_test3['best_preprocess'])\n",
    "\n",
    "print(gaussian_model_results_test1['best_preprocess'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now testing both against their test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=10.0)\n",
      "0.7346197502837684\n",
      "0.11\n",
      "(Initial Standardization/Resizing)(Blurring, Type = b, Dimension = (128, 128), Kernel = (3, 3), sigma_x = 0, sigma_y = 0)(Pool, pool_size = (8, 8), pooling_function = <function amax at 0x11194eca0>)\n"
     ]
    }
   ],
   "source": [
    "from eval_on_test import make_preds\n",
    "#Bernoulli\n",
    "best_bernoulli_model = bernoulli_model_results_test3\n",
    "\n",
    "\n",
    "print(best_bernoulli_model['best_model'])\n",
    "print(best_bernoulli_model['best_score'])\n",
    "print(best_bernoulli_model['best_thresh'])\n",
    "print(best_bernoulli_model['best_preprocess'])\n",
    "\n",
    "# print('Model Accuracy:',best_bernoulli_model.score(test_x,test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_data['label']\n",
    "x = test_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features':            0          1          2          3          4          5    \\\n",
       " 3949  0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       " 230   0.000000  36.666668  33.000000  32.000000  48.222221  49.888889   \n",
       " 354   0.000000   0.000000   0.000000   0.000000   9.000000  25.111111   \n",
       " 2736  0.000000   0.000000   0.000000   0.000000   0.222222   0.333333   \n",
       " 3540  0.000000   0.000000   0.000000   0.666667   9.888889  22.222221   \n",
       " ...        ...        ...        ...        ...        ...        ...   \n",
       " 1776  2.000000  14.444445  31.000000   2.000000   2.444444   2.333333   \n",
       " 1791  0.333333   2.000000   2.000000   1.777778   2.000000   2.000000   \n",
       " 2099  0.000000   0.000000   2.666667   2.888889   3.222222   4.000000   \n",
       " 53    1.000000   1.000000   1.000000   1.000000   1.000000   1.555556   \n",
       " 3857  3.777778   2.444444   3.111111   4.111111   3.666667   3.333333   \n",
       " \n",
       "             6          7          8          9    ...        246        247  \\\n",
       " 3949   0.000000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   \n",
       " 230   68.666664  37.777779  39.222221  59.888889  ...  37.333332  40.777779   \n",
       " 354   60.333332  70.666664  59.222221  65.111115  ...  62.888889  63.555557   \n",
       " 2736   0.000000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   \n",
       " 3540  85.555557  83.555557  76.000000  61.000000  ...  74.888885  90.000000   \n",
       " ...         ...        ...        ...        ...  ...        ...        ...   \n",
       " 1776  35.777779  46.888889  50.333332  35.444443  ...  36.000000  29.444445   \n",
       " 1791   1.888889  14.666667  15.222222   5.333333  ...  56.888889  63.444443   \n",
       " 2099   5.000000   4.777778   4.777778   3.666667  ...   3.000000   3.444444   \n",
       " 53    30.666666  67.555557  64.555557  28.333334  ...  71.111115  51.333332   \n",
       " 3857  13.000000  35.333332  44.666668  26.666666  ...  57.888889  75.888885   \n",
       " \n",
       "             248        249        250        251        252        253  \\\n",
       " 3949   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       " 230   72.222221  33.888889  43.333332  19.222221  18.444445  15.777778   \n",
       " 354   47.666668  75.888885  29.777779   5.444445   0.000000   0.000000   \n",
       " 2736   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       " 3540  70.888885  70.777779  48.444443   7.111111   0.000000   0.000000   \n",
       " ...         ...        ...        ...        ...        ...        ...   \n",
       " 1776  26.222221  16.555555  19.888889  24.444445  47.666668  69.111115   \n",
       " 1791  68.888885  56.888889  80.111115  32.000000   4.888889   3.222222   \n",
       " 2099   3.222222   3.111111   3.555556   3.666667   4.000000   4.000000   \n",
       " 53    68.666664  51.555557  21.222221   1.444444   1.000000   1.000000   \n",
       " 3857  58.222221  66.888885  66.888885  92.222221  87.888885  88.555557   \n",
       " \n",
       "              254        255  \n",
       " 3949    0.000000   0.000000  \n",
       " 230    13.888889   0.000000  \n",
       " 354     0.000000   0.000000  \n",
       " 2736    0.000000   0.000000  \n",
       " 3540    0.000000   0.000000  \n",
       " ...          ...        ...  \n",
       " 1776  102.444443  74.222221  \n",
       " 1791    3.222222   1.111111  \n",
       " 2099    0.000000   0.000000  \n",
       " 53      1.000000   1.000000  \n",
       " 3857   57.555557   2.000000  \n",
       " \n",
       " [1380 rows x 256 columns],\n",
       " 'probs': array([4.34183614e-35, 1.00000000e+00, 2.01514512e-03, ...,\n",
       "        9.99931675e-01, 9.92519439e-01, 8.72403903e-01]),\n",
       " 'preds': array([0, 1, 0, ..., 1, 1, 1]),\n",
       " 'f1 score': 0.7162089391491655,\n",
       " 'accuracy': 0.6181159420289855,\n",
       " 'confusion_matrix': array([[188, 458],\n",
       "        [ 69, 665]])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_bernoulli_predictions = make_preds(x,y,[('resize',[(256,256),(128,128)]),('blur',['b',(128,128),(3,3),0,0]),('pool',[(8,8),np.max])],\n",
    "          best_bernoulli_model['best_model'],best_bernoulli_model['best_thresh'])\n",
    "\n",
    "top_bernoulli_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=1e-11)\n",
      "0.7443428021184401\n",
      "0.060000000000000005\n",
      "(Initial Standardization/Resizing)(Pool, pool_size = (16, 16), pooling_function = <function amax at 0x11194eca0>)\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli\n",
    "best_gaussian_model = gaussian_model_results_test1\n",
    "\n",
    "\n",
    "print(best_gaussian_model['best_model'])\n",
    "print(best_gaussian_model['best_score'])\n",
    "print(best_gaussian_model['best_thresh'])\n",
    "print(best_gaussian_model['best_preprocess'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features':       0    1    2    3    4    5    6   7    8    9   ...   54   55   56   57  \\\n",
       " 3949   0    0    0    0    0    0    0   0    5  126  ...  123   78    0    0   \n",
       " 230   96  110  124  127  127  125  126  98  110  127  ...  127   23  108   39   \n",
       " 354    0   30  114  127  125  126   13   0    0  127  ...  121    0    0    1   \n",
       " 2736   0    1    1   18   18    0    0   0    0    3  ...  117    1    0    0   \n",
       " 3540   0   10  126  124  127  126   11   0    0  126  ...  127    2    8  116   \n",
       " ...   ..  ...  ...  ...  ...  ...  ...  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       " 1776   4   71  117  127  126  119    6   4    6  126  ...   93   26  125  126   \n",
       " 1791   9    4  102  125  115  118    4   5   12  105  ...   61    8    5   74   \n",
       " 2099   0    5    7   14    7    5    7   0    0   67  ...   10    0    0    4   \n",
       " 53     1    1  123  127  124  122    1   1    1  127  ...  127    1    1  124   \n",
       " 3857   9    9  115  127  124  125  122   8   17  113  ...  126  116   64   98   \n",
       " \n",
       "        58   59   60   61   62   63  \n",
       " 3949    0    0    0    0    0    0  \n",
       " 230   123  127  127  125   30   19  \n",
       " 354   127  127  126  126    3    0  \n",
       " 2736    0    0    1    2    1    0  \n",
       " 3540  123  125  126  111   57    0  \n",
       " ...   ...  ...  ...  ...  ...  ...  \n",
       " 1776   81   67   61   58   87  121  \n",
       " 1791  101  106  123  107    6    4  \n",
       " 2099    6    7    8    5    5    0  \n",
       " 53    127  127  127  124   29    1  \n",
       " 3857   78   90   90  124  127  122  \n",
       " \n",
       " [1380 rows x 64 columns],\n",
       " 'probs': array([0.99999997, 0.99999981, 0.63917464, ..., 0.00227248, 0.99671088,\n",
       "        1.        ]),\n",
       " 'preds': array([1, 1, 1, ..., 0, 1, 1]),\n",
       " 'f1 score': 0.7286288009179576,\n",
       " 'accuracy': 0.6572463768115943,\n",
       " 'confusion_matrix': array([[272, 374],\n",
       "        [ 99, 635]])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_gaussian_predictions = make_preds(x,y,[('resize',[(256,256),(128,128)]),('pool',[(16,16),np.max])],\n",
    "          best_gaussian_model['best_model'],best_gaussian_model['best_thresh'])\n",
    "\n",
    "top_gaussian_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling Final Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('nb_model_results/top_bernoulli_model_predictions.pickle', 'wb') as handle:\n",
    "    pickle.dump(top_bernoulli_predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('nb_model_results/top_gaussian_model_predictions.pickle', 'wb') as handle:\n",
    "    pickle.dump(top_gaussian_predictions, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying the top models again with new resizing ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pickle.load(open('Amit/Labeled Data/train_data.pkl','rb'))\n",
    "train_x,train_y = all_data.iloc[:,:-1],all_data.iloc[:,-1]\n",
    "del all_data\n",
    "gc.collect()\n",
    "\n",
    "from automate_optimal_model_dev import automate_optimal_model_dev\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better Model Identified by Resizing Images to (16, 16): 0.6876712328767124\n",
      "Better Model Identified W/ Pooling, Score = 0.7214936652589464\n",
      "Better Model Identified W/ Pooling, Score = 0.724383103304057\n"
     ]
    }
   ],
   "source": [
    "bernoulli_retest_1 = automate_optimal_model_dev(X = resize_dataset(train_x,(256,256),(32,32)),y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['blur','bin/crop','pool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features':        0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       " 54    127  126  115 -107  126  122  106  127  127  125  126  127  127  122   \n",
       " 2602 -104  -44  -20  -69  -43  119   42   68  -38  -32  118  -26  -47  -29   \n",
       " 3433 -125  127  127 -125  127  -10   -7  127  125   -6   -7  125  104  120   \n",
       " 235   124  114  116  -65  127  125  124  127  124  112  125  127  -87  123   \n",
       " 1806 -125  126  127 -125  127  -56  -56   99  126  -37  -29  126  -31  -31   \n",
       " ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 3330 -128  127  127 -128  127  101  122  127 -119  103  117  127 -128  127   \n",
       " 70    -89  -20  -25  -77  -65  -20  -20  -41  -71  110  120  -69  -93  -23   \n",
       " 132   127  127  126  126  127   -1  126  127  127   -1   72  127  127   -1   \n",
       " 2014    7  121   96   84  126  126  126  116  125  121  125  122  119  119   \n",
       " 1931  123  125  106  125  -26  -13  -13  125  115  -13   78  120  114  107   \n",
       " \n",
       "        14   15  \n",
       " 54    126  122  \n",
       " 2602  -36  -63  \n",
       " 3433  102  122  \n",
       " 235    90   98  \n",
       " 1806  -31  122  \n",
       " ...   ...  ...  \n",
       " 3330  127  127  \n",
       " 70    -26 -107  \n",
       " 132   124  127  \n",
       " 2014  121  117  \n",
       " 1931  122  122  \n",
       " \n",
       " [3220 rows x 16 columns],\n",
       " 'best_model': BernoulliNB(alpha=10.0),\n",
       " 'best_params': {'alpha': 10.0},\n",
       " 'oos_probs': 54      0.655831\n",
       " 2602    0.114190\n",
       " 3433    0.716554\n",
       " 235     0.592581\n",
       " 1806    0.813060\n",
       "           ...   \n",
       " 3330    0.345203\n",
       " 70      0.091039\n",
       " 132     0.798496\n",
       " 2014    0.663715\n",
       " 1931    0.564773\n",
       " Name: label, Length: 3220, dtype: float64,\n",
       " 'oos_preds': array([1, 1, 1, ..., 1, 1, 1]),\n",
       " 'best_thresh': 0.11,\n",
       " 'best_score': 0.724383103304057,\n",
       " 'best_preprocess': '(Initial Standardization/Resizing to (16, 16))(Pool, pool_size = (4, 4), pooling_function = <function amax at 0x000001D1BB420E50>)'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulli_retest_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = pickle.load(open('Amit/Labeled Data/test_data.pkl','rb'))\n",
    "y = test_data['label']\n",
    "x = test_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features':        0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       " 3949   60   92   87   86   97   89  104   82   80   70   93  100   78   95   \n",
       " 230   103  126  124  121  124  123  127  119  115  127  120  115  111  125   \n",
       " 354   106  101  104   89  104  121  122  127  106  126  124   91   57  121   \n",
       " 2736    1   95   83    1   53  118  125   88   58   89  126  126    1   74   \n",
       " 3540   58  116  120   62   99  110  101  101  125  107  108  121  125  119   \n",
       " ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 1776   84   93   86   92   99   80   80   89  106   95   79   86   86   89   \n",
       " 1791   11   79   85   42   67   76   92   66   60   86   98   50   41   87   \n",
       " 2099    7   74   95   15   86  105  100   88   90   84   95   45    4   96   \n",
       " 53     56  127  127   37  110  126  126  111  126  119  124  122  114  124   \n",
       " 3857   66   88   96   88   86  101  107  108  101   93  111  120   70   77   \n",
       " \n",
       "        14   15  \n",
       " 3949  111   92  \n",
       " 230   127  102  \n",
       " 354   124   56  \n",
       " 2736   80   14  \n",
       " 3540  122   95  \n",
       " ...   ...  ...  \n",
       " 1776   64   61  \n",
       " 1791   91   21  \n",
       " 2099   83    4  \n",
       " 53    127  102  \n",
       " 3857   76  121  \n",
       " \n",
       " [1380 rows x 16 columns],\n",
       " 'probs': array([0.68897604, 0.68897604, 0.68897604, ..., 0.68897604, 0.68897604,\n",
       "        0.68897604]),\n",
       " 'preds': array([1, 1, 1, ..., 1, 1, 1]),\n",
       " 'f1 score': 0.6963946869070208,\n",
       " 'accuracy': 0.5362318840579711,\n",
       " 'confusion_matrix': array([[  6, 640],\n",
       "        [  0, 734]], dtype=int64)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval_on_test import make_preds\n",
    "\n",
    "top_bernoulli_model_retest = make_preds(x,y,[('resize',[(256,256),(16,16)]),('pool',[(4,4),np.max])],\n",
    "          bernoulli_retest_1['best_model'],bernoulli_retest_1['best_thresh'])\n",
    "\n",
    "top_bernoulli_model_retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_model_retest1 = automate_optimal_model_dev(X = resize_dataset(train_x,(256,256),(32,32)),y = train_y,\n",
    "                                    model = BernoulliNB(),\n",
    "                                    param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
    "                                    preprocessing_eval_order = ['blur','bin/crop','pool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e52079bc96b761e1a7c920106f5ae346703f4f6625fb75db0993ce8babfb0b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('w207_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
